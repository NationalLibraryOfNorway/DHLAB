{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La oss jobbe med dokumenter lasta ned fra Internett, Språkrådet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import dhlab.nbtext as nb\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funksjonalitet for å sjekke målform og mellomlagre nynorske dokumenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generating = False\n",
    "\n",
    "def char_ngram_freqs(n=3, lang='nob', epochs=4):\n",
    "    ngram = lambda x: [x[i:i+n] for i in range(len(x))] \n",
    "    sents = []\n",
    "    freqs = Counter()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        sents += nb.sentences(nb.book_urn(limit=20, lang=lang, period=(1990, 2020)))\n",
    "    \n",
    "    trigrams = list(map(ngram, sents))\n",
    "    for t in trigrams: \n",
    "        freqs.update(t)\n",
    "    \n",
    "    return freqs\n",
    "\n",
    "def ngramify(txt, n=3, c=300):\n",
    "    ngram = lambda x: [x[i:i+n] for i in range(len(x))]\n",
    "    freqs = Counter()\n",
    "    freqs.update(ngram(txt))\n",
    "    \n",
    "    return freqs.most_common(c)\n",
    "    \n",
    "\n",
    "def nobornno(text, nob, nno):\n",
    "    return 1 - distance.cosine(nno, text) > 1 - distance.cosine(nob, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating character n-gram frequences from random sentences in the bibliography between 1990 and 2020;\n",
    "# Note that this can take a while ...\n",
    "if generating == True:\n",
    "    nob = char_ngram_freqs(epochs = 10)\n",
    "    nno = char_ngram_freqs(lang='nno', epochs = 10)\n",
    "\n",
    "    json.dump(nob, open('trigram_lang_model/nob_trilangmodel.json','w', encoding='utf-8'))\n",
    "    json.dump(nno, open('trigram_lang_model/nno_trilangmodel.json','w', encoding='utf-8'))\n",
    "else:\n",
    "    nob = json.load(open('trigram_lang_model/nob_trilangmodel.json'))\n",
    "    nno = json.load(open('trigram_lang_model/nno_trilangmodel.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the pages in a document is Nynorsk or Bokmål,\n",
    "# and chaching if we can assume that it is.\n",
    "def check_text(text):\n",
    "        doc = dict(ngramify(text, n = 3, c = 300))\n",
    "        df = pd.DataFrame.from_dict({'nno':nno, 'nob':nob, 'doc':doc}, \n",
    "                                    orient='index').transpose().fillna(0)\n",
    "        return {'nno': 1 - distance.cosine(df['nno'], df['doc']), 'nob': 1 - distance.cosine(df['nob'], df['doc'])}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_text('dette er galt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
